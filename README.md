# ğŸš— Vehicle Appraisal Pre-Check

> **AI-powered validation system that ensures appraisal evidence is complete before human review begins**

---

## ğŸ¯ What It Does

**Prevents incomplete appraisals from reaching human appraisers** by automatically:

- ğŸ“¸ **Analyzes photos** to extract vehicle angles, odometer, VIN, and damage
- ğŸ” **Checks completeness** against required evidence standards
- âš ï¸ **Detects risks** using historical context from similar appraisals
- ğŸ“Š **Calculates readiness score** (0-100) to route decisions confidently
- ğŸ“ **Maintains audit trail** of every AI decision for transparency

---

## ğŸ”„ How It Works

```mermaid
graph TD
    A[ğŸ“¤ User Uploads<br/>Vehicle Photos] --> B[ğŸ“¸ Vision Extraction<br/>GPT-4 Vision]
    B --> C{ğŸ” Evidence<br/>Complete?}
    C -->|Yes| D[âœ… Ready<br/>Score â‰¥ 80]
    C -->|Partial| E[âš ï¸ Needs More<br/>Score 50-79]
    C -->|No| F[âŒ Escalate<br/>Score < 50]
    
    B --> G[ğŸ” RAG Search<br/>Similar Appraisals]
    G --> H[âš ï¸ Risk Detection<br/>Historical Patterns]
    H --> I[ğŸ“Š Scoring Engine<br/>0-100 Points]
    I --> C
    
    D --> J[âœ… Route to<br/>Appraiser]
    E --> K[ğŸ“‹ Request<br/>More Evidence]
    F --> L[ğŸ”´ Senior<br/>Review]
    
    style A fill:#e3f2fd
    style B fill:#bbdefb
    style C fill:#fff9c4
    style D fill:#c8e6c9
    style E fill:#ffe082
    style F fill:#ef5350
    style G fill:#f3e5f5
    style H fill:#ffccbc
    style I fill:#b2dfdb
```

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    subgraph Frontend
        A[Streamlit UI<br/>ğŸ“± User Interface]
    end
    
    subgraph AI Assistants
        MCP_CLIENT[Claude Desktop<br/>ğŸ¤– AI Assistant]
    end
    
    subgraph Backend API
        B[FastAPI<br/>ğŸš€ REST Endpoints]
        C[Pipeline Orchestrator<br/>âš™ï¸ Agent Controller]
    end
    
    subgraph MCP Server
        MCP[MCP Server<br/>ğŸ”Œ Model Context Protocol]
    end
    
    subgraph AI Processing
        D[Vision Module<br/>ğŸ‘ï¸ GPT-4 Vision]
        E[Agent Framework<br/>ğŸ¤– LangChain]
        F[RAG System<br/>ğŸ” Vector Search]
        G[Risk Scanner<br/>âš ï¸ Pattern Detection]
        H[Scoring Engine<br/>ğŸ“Š 0-100 Points]
    end
    
    subgraph Data Layer
        I[(Supabase<br/>ğŸ—„ï¸ PostgreSQL)]
        J[Storage<br/>ğŸ“¦ Photo Artifacts]
        K[Vector DB<br/>ğŸ”¢ Embeddings]
    end
    
    A -->|HTTP| B
    MCP_CLIENT -->|stdio| MCP
    MCP -->|HTTP| B
    B --> C
    C --> D
    C --> E
    E --> F
    E --> G
    E --> H
    D --> I
    E --> I
    F --> K
    B --> J
    
    style A fill:#e1f5fe
    style MCP_CLIENT fill:#fff3e0
    style MCP fill:#f3e5f5
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#e8f5e9
    style E fill:#fff9c4
    style F fill:#fce4ec
    style G fill:#ffebee
    style H fill:#e0f2f1
    style I fill:#e3f2fd
    style J fill:#f1f8e9
    style K fill:#fce4ec
```

---

## ğŸ¤– MCP Integration (Model Context Protocol)

**Enable AI assistants like Claude Desktop to query appraisal data directly**

The MCP server exposes read-only tools that allow AI assistants to interact with the appraisal system, making it easy to check status, evidence completeness, risk flags, and audit logs through natural language.

### Architecture

```mermaid
graph TD
    A[Claude Desktop<br/>ğŸ¤– AI Assistant] -->|stdio<br/>MCP Protocol| B[MCP Server<br/>ğŸ”Œ apps/mcp]
    B -->|HTTP/REST| C[FastAPI API<br/>ğŸš€ backend/app]
    C --> D[(Supabase<br/>ğŸ—„ï¸ Database)]
    
    style A fill:#fff3e0
    style B fill:#f3e5f5
    style C fill:#e1f5fe
    style D fill:#e3f2fd
```

### Available MCP Tools

| Tool | Description |
|------|-------------|
| `get_appraisal_status` | Get status, readiness score, and decision |
| `check_evidence_completeness` | Check missing evidence and photo angles |
| `get_risk_flags` | Get all risk flags by severity |
| `get_decision_readiness` | Get readiness assessment with score breakdown |
| `get_ledger_events` | Get complete audit ledger (event log) |

### Quick Setup

**1. Start MCP Server (with Docker)**
```bash
# Start all services including MCP
docker-compose --profile mcp up -d

# Or run MCP server locally
cd apps/mcp
pip install -r requirements.txt
export API_BASE_URL=http://localhost:8001
python server.py
```

**2. Connect Claude Desktop**

Edit Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json` on Mac):

```json
{
  "mcpServers": {
    "vehicle-appraisal": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "--network=vehicle-appraisal-app_appraisal-network",
        "-e",
        "API_BASE_URL=http://api:8000",
        "vehicle-appraisal-app-mcp:latest",
        "python",
        "server.py"
      ]
    }
  }
}
```

**3. Restart Claude Desktop** - MCP tools will be available automatically!

### Example Usage

Once connected, you can ask Claude Desktop:
- *"What's the status of appraisal QE43?"*
- *"Check if appraisal ABC1 has complete evidence"*
- *"Show me risk flags for appraisal XYZ9"*
- *"Get the readiness score breakdown for appraisal DEF2"*

See [`apps/mcp/README.md`](apps/mcp/README.md) for detailed documentation.

---

## âœ¨ Key Features

### ğŸ¯ **Smart Evidence Validation**
```
Required Evidence:
â”œâ”€â”€ ğŸ“¸ Photo Coverage (48 pts)
â”‚   â”œâ”€â”€ Front view
â”‚   â”œâ”€â”€ Rear view
â”‚   â”œâ”€â”€ Left side
â”‚   â”œâ”€â”€ Right side
â”‚   â”œâ”€â”€ Interior
â”‚   â””â”€â”€ Odometer reading
â”œâ”€â”€ â²ï¸ Odometer Confidence (15 pts)
â”œâ”€â”€ ğŸ”‘ VIN Detection (10 pts)
â””â”€â”€ ğŸ“ Notes Quality (20 pts)
```

### ğŸ¤– **Agentic Processing**
- **Adaptive workflow**: AI agent decides which tools to use and when
- **Self-correcting**: Automatically retries failed steps
- **Context-aware**: Uses RAG to find similar historical cases
- **Transparent**: Every decision logged in immutable ledger

### ğŸ“Š **Decision Routing**
```
Score â‰¥ 80  â†’ âœ… Ready to Decide
Score 50-79 â†’ âš ï¸ Needs More Evidence
Score < 50  â†’ ğŸ”´ Escalation Required
```

### ğŸ” **RAG-Enhanced Analysis**
- Searches historical appraisals for similar patterns
- Identifies risks based on past outcomes
- Provides context for confidence scoring

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Supabase account (database + storage)
- OpenAI API key
- Docker (optional, for local dev)

### 1ï¸âƒ£ Setup Environment

   ```bash
# Clone repository
   git clone <repository-url>
   cd vehicle-appraisal-app
   
# Backend environment
   cp backend/.env.example backend/.env
# Edit backend/.env with your credentials

# Frontend environment
   cp frontend/.env.example frontend/.env
# Edit frontend/.env with API URL
```

### 2ï¸âƒ£ Database Setup

Run migrations in Supabase SQL Editor (in order):
1. `migrations/001_core.sql` - Core schema
2. `migrations/002_rag_embeddings.sql` - Vector search
3. `migrations/003_short_ids.sql` - Short IDs

Create storage bucket: `appraisal-artifacts`

### 3ï¸âƒ£ Run Locally

**Option A: Docker (Recommended)**
   ```bash
# Start API and UI
   docker-compose up

# Or include MCP server for AI assistant integration
docker-compose --profile mcp up
```
- API: http://localhost:8001
- UI: http://localhost:8502
- MCP: Available via stdio (for Claude Desktop)

**Option B: Manual**
   ```bash
# Backend
   cd backend
   pip install -r requirements.txt
   uvicorn app.main:app --reload
   
# Frontend (new terminal)
   cd frontend
   pip install -r requirements.txt
   streamlit run app.py
   ```

---

## ğŸ“‹ User Workflow

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Streamlit UI
    participant API as FastAPI
    participant AI as AI Pipeline
    participant DB as Supabase

    U->>UI: 1. Enter vehicle details
    UI->>API: Create appraisal
    API->>DB: Store metadata
    
    U->>UI: 2. Upload photos (1-3)
    UI->>API: Upload photos
    API->>DB: Store artifacts
    API->>AI: Background vision extraction
    
    U->>UI: 3. Start AI analysis
    UI->>API: Run pipeline
    API->>AI: Agentic processing
    AI->>AI: Extract vision data
    AI->>AI: Check evidence completeness
    AI->>AI: RAG search similar cases
    AI->>AI: Scan for risks
    AI->>AI: Calculate readiness score
    AI->>DB: Store results + ledger
    
    U->>UI: 4. View results
    UI->>API: Get appraisal
    API->>DB: Fetch results
    UI->>U: Display score + recommendations
```

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Streamlit | User interface |
| **Backend** | FastAPI | REST API |
| **Database** | Supabase (PostgreSQL) | Data storage |
| **Storage** | Supabase Storage | Photo artifacts |
| **Vector DB** | pgvector | Embedding search |
| **AI Vision** | GPT-4 Vision | Photo analysis |
| **AI Text** | GPT-4o-mini | Agent reasoning |
| **Agent** | LangChain | Orchestration |
| **MCP** | Model Context Protocol | AI assistant integration |
| **Deployment** | Render.com | Hosting |

---

## ğŸ“Š Scoring Breakdown

```
Total Score: 100 points

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category                â”‚ Pointsâ”‚ Description        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“¸ Photo Coverage       â”‚  48   â”‚ 6 angles Ã— 8 pts  â”‚
â”‚ â²ï¸ Odometer Confidence  â”‚  15   â”‚ Reading quality   â”‚
â”‚ ğŸ”‘ VIN Presence         â”‚  10   â”‚ Optional bonus    â”‚
â”‚ ğŸ“ Notes Consistency    â”‚  20   â”‚ Quality check     â”‚
â”‚ âš ï¸ Risk Penalties       â”‚  -7   â”‚ Deductions        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Environment Variables

### Backend (`backend/.env`)
```bash
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY=xxx
SUPABASE_STORAGE_BUCKET=appraisal-artifacts
OPENAI_API_KEY=sk-xxx
ENABLE_RAG=true
```

### Frontend (`frontend/.env`)
```bash
API_BASE_URL=http://localhost:8000
API_TIMEOUT_SECONDS=60
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/appraisals` | Create appraisal with photos |
| `POST` | `/api/appraisals/create` | Create appraisal (no photos) |
| `POST` | `/api/appraisals/{id}/photos/upload` | Upload single photo |
| `POST` | `/api/appraisals/{id}/run` | Start AI analysis |
| `GET` | `/api/appraisals/{id}` | Get appraisal results |
| `GET` | `/api/appraisals/{id}/photos` | Get all photos |
| `GET` | `/api/appraisals/{id}/ledger` | Get audit trail |
| `GET` | `/healthz` | Health check |
| `GET` | `/readyz` | Readiness check |

---

## ğŸš¢ Deployment

### Render.com (Free Tier Compatible)

1. **Connect GitHub** repository to Render
2. **Create Blueprint** using `render.yaml`
3. **Set environment variables** in Render dashboard
4. **Deploy** - Both services auto-deploy

**Note**: Free tier services spin down after 15 min inactivity. First request may take 30-60s (cold start).

---

## ğŸ“ˆ Performance

- **Vision extraction**: ~10-15s per photo (background)
- **Full pipeline**: ~2 minutes (agentic mode)
- **Concurrent uploads**: Up to 3 photos in parallel
- **RAG search**: <500ms (with pgvector HNSW index)

---

## ğŸ” Monitoring & Debugging

### Health Checks
```bash
# Liveness
curl http://localhost:8000/healthz

# Readiness (checks Supabase, OpenAI, RAG)
curl http://localhost:8000/readyz
```

### View Audit Ledger
Every decision is logged in the immutable ledger:
- Navigate to "View Appraisal" â†’ "Event Log" tab
- Download JSON for full audit trail

---

## ğŸ§ª Testing

See `TESTING_PLAN.md` for comprehensive testing strategy.

---

## ğŸ“š Project Structure

```
vehicle-appraisal-app/
â”œâ”€â”€ backend/              # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py      # API endpoints
â”‚   â”‚   â”œâ”€â”€ pipeline.py   # Agent orchestrator
â”‚   â”‚   â”œâ”€â”€ vision.py     # Photo analysis
â”‚   â”‚   â”œâ”€â”€ risk.py       # Risk detection
â”‚   â”‚   â””â”€â”€ scoring.py    # Readiness scoring
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/            # Streamlit UI
â”‚   â”œâ”€â”€ app.py           # Main app
â”‚   â””â”€â”€ components/      # UI components
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ mcp/             # MCP server
â”‚       â”œâ”€â”€ server.py    # MCP server implementation
â”‚       â””â”€â”€ tools/       # MCP tools
â”œâ”€â”€ shared/              # Shared packages
â”‚   â”œâ”€â”€ agent/           # LangChain agent
â”‚   â”œâ”€â”€ rag/             # RAG functionality
â”‚   â””â”€â”€ ledger/           # Audit ledger
â”œâ”€â”€ migrations/          # Database migrations
â”œâ”€â”€ docker-compose.yml    # Local development
â””â”€â”€ render.yaml          # Render deployment
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“„ License

[Your License Here]

---

## ğŸ†˜ Support

For issues and questions:
- Open a GitHub issue
- Check `SETUP.md` for detailed setup instructions
- Review `PROGRESS.md` for build status

---

<div align="center">

**Built with â¤ï¸ using FastAPI, Streamlit, LangChain, and OpenAI**

[ğŸš€ Get Started](#-quick-start) â€¢ [ğŸ“– Documentation](SETUP.md) â€¢ [ğŸ› Report Issue](https://github.com/your-repo/issues)

</div>
